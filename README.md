# Violence Detection System

<div align="center">

### AI-powered Real-time Violence Detection for Intelligent Surveillance

![Python](https://img.shields.io/badge/Python-3.11+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![YOLO](https://img.shields.io/badge/YOLOv8-00FFFF?style=for-the-badge&logo=yolo&logoColor=black)
![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)

</div>

---

## Executive Summary

A comprehensive AI-driven violence detection system designed for intelligent video surveillance. The system leverages YOLOv8 neural networks combined with advanced preprocessing techniques to identify violent behavior in real-time video streams with minimal latency and high accuracy.

**Target Use Cases:**
- Surveillance in public spaces (airports, transit hubs, retail)
- Critical infrastructure protection
- Venue safety monitoring
- Emergency response systems

---

## Key Features

| Feature | Capability |
|---------|-----------|
| **Detection Performance** | Real-time (<2s latency), 85%+ accuracy |
| **Processing** | Optimized inference (PyTorch & ONNX) |
| **Scalability** | Support for 10-20 concurrent video streams |
| **Deployment** | Docker containerization for easy deployment |
| **Flexibility** | Multiple inference backends (PyTorch/ONNX) for different hardware |

---

## System Architecture

The system is built on a modular microservices architecture:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          VIDEO INPUT SOURCES                        ‚îÇ
‚îÇ  IP Cameras (RTSP) ‚îÇ Webcams ‚îÇ Video Files          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          MEDIA PROCESSING LAYER                     ‚îÇ
‚îÇ  Frame Extraction ‚îÇ Preprocessing ‚îÇ Streaming       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ       AI DETECTION SERVICE                          ‚îÇ
‚îÇ  YOLOv8 (PyTorch/ONNX) ‚îÇ OpenCV ‚îÇ GPU/CPU Inference ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         BACKEND SERVICES                            ‚îÇ
‚îÇ  FastAPI ‚îÇ PostgreSQL ‚îÇ Redis ‚îÇ Authentication      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      USER-FACING INTERFACES                         ‚îÇ
‚îÇ  Web Dashboard (React) ‚îÇ Mobile App (Flutter)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Technical Specifications

### AI Model

- **Base Architecture**: YOLOv8 Nano (lightweight, optimized)
- **Training Data**: RWF-2000 violence detection dataset
- **Inference Modes**:
  - **PyTorch**: Full precision, best accuracy
  - **ONNX**: Quantized, optimized for CPU/edge devices
- **Input Formats**: 320√ó320, 384√ó384, 512√ó512 (configurable)

### Performance Characteristics

| Metric | PyTorch | ONNX (CPU) |
|--------|---------|-----------|
| Latency (GPU) | 1-3ms | N/A |
| Latency (CPU) | 10-30ms | 2-5ms |
| Model Size | 12MB | 4MB |
| Memory Usage | 300MB+ | 50MB+ |
| Accuracy | 100% baseline | ~98% vs PyTorch |

### Infrastructure

- **Backend Framework**: FastAPI (async, high-performance)
- **Database**: PostgreSQL (structured data), Redis (caching)
- **Containerization**: Docker + Docker Compose
- **Streaming**: RTSP protocol via MediaMTX
- **Security**: JWT authentication, encrypted communications

---

## Project Structure

```
violence-detection/
‚îú‚îÄ‚îÄ ai_service/                    # AI Detection Engine
‚îÇ   ‚îú‚îÄ‚îÄ detection/                 # Detection implementations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pytorch_detector.py    # YOLOv8 PyTorch inference
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ onnx_inference.py      # YOLOv8 ONNX inference
‚îÇ   ‚îú‚îÄ‚îÄ common/preprocessing/      # Data preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ models/weights/            # Model weights storage
‚îÇ   ‚îú‚îÄ‚îÄ config/                    # Configuration management
‚îÇ   ‚îú‚îÄ‚îÄ utils/                     # Utilities & helpers
‚îÇ   ‚îî‚îÄ‚îÄ tests/                     # Comprehensive testing suite
‚îÇ
‚îú‚îÄ‚îÄ backend/                       # FastAPI Backend Service
‚îÇ   ‚îú‚îÄ‚îÄ main.py                    # Application entry point
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core/                  # Configuration & logging
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ domain/                # Business entities
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ application/           # Use cases & business logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ infrastructure/        # External integrations
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ presentation/          # API endpoints
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml         # Service orchestration
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile                 # Container definition
‚îÇ
‚îú‚îÄ‚îÄ admin-dashboard/               # React Web Dashboard (UI Layer)
‚îú‚îÄ‚îÄ flutter-app/                   # Flutter Mobile App (UI Layer)
‚îú‚îÄ‚îÄ utils/                         # Utility scripts
‚îî‚îÄ‚îÄ docs/                          # Documentation
```

---

## Technology Stack

### Core Technologies
- **Python 3.11+**: Primary development language
- **PyTorch**: Deep learning framework
- **YOLOv8**: Object detection model
- **ONNX Runtime**: Cross-platform inference
- **FastAPI**: Async web framework
- **OpenCV**: Computer vision preprocessing

### Infrastructure & DevOps
- **Docker**: Containerization
- **Docker Compose**: Multi-container orchestration
- **PostgreSQL**: Relational database
- **Redis**: In-memory caching & queuing
- **MediaMTX**: RTSP streaming server

### Frontend
- **React**: Web dashboard
- **Flutter**: Cross-platform mobile app

---

## System Requirements

### Development
- Python 3.11 or higher
- 8GB RAM minimum
- CUDA 11.8+ (optional, for GPU acceleration)

### Production
- Docker & Docker Compose
- GPU (recommended) or CPU (supported)
- 16GB+ RAM
- 50GB+ storage (for video logs)

---

## Quick Overview

### Detection Pipeline

1. **Frame Acquisition**: Frames from RTSP streams, webcams, or files
2. **Preprocessing**: Resize, normalize, prepare for neural network
3. **Inference**: YOLOv8 forward pass (GPU/CPU)
4. **Post-processing**: NMS filtering, confidence thresholding
5. **Alert Generation**: Trigger notifications if violence detected
6. **Logging**: Store results in database for analytics

### Quality Assurance

The project includes comprehensive testing:
- **Unit Tests**: test cases for core components
- **Integration Tests**: End-to-end detection workflows
- **Performance Tests**: Latency & throughput benchmarks
- **Accuracy Tests**: Model performance validation

---

## Notable Features

### Multi-Backend Support
Deploy the same trained model across different platforms:
- **PyTorch backend**: Full precision inference (GPU-optimized)
- **ONNX backend**: Quantized inference (CPU-optimized)
- **Automatic selection**: Based on available hardware

### Modular Architecture
Each component is independently deployable:
- Detection service can run standalone
- Backend API is independent of frontend
- Easy to swap inference engines

### Comprehensive Logging
- Frame-by-frame detection results
- Performance metrics tracking
- Event history & analytics
- Audit trails for security

---

## Development Team

**Lead Developer**: tiao051

The project is actively maintained and welcomes community contributions.

---

## Acknowledgments

### Technologies & Resources
- **YOLOv8**: Ultralytics for state-of-the-art object detection
- **PyTorch**: Meta for deep learning framework
- **OpenCV**: Computer vision community
- **FastAPI**: Starlette team for async web framework

### Datasets
- **RWF-2000**: Real World Fight Dataset for model training

---

## License

This project is provided for educational and research purposes.

---

## Contributing

We welcome contributions! Please refer to the individual component repositories:
- [Backend Service](backend/README.md)
- [AI Service](ai_service/README.md)

---

## Acknowledgments

**ü§ù Special Thanks To**

| Category | Resource |
|----------|----------|
| üß† **AI & ML** | YOLOv8 (Ultralytics), PyTorch, ONNX Runtime |
| üìä **Datasets** | RWF-2000 Violence Detection Dataset |
| üõ†Ô∏è **Tools** | OpenCV, Docker, FastAPI |

---

<div align="center">

### üìñ Documentation

For detailed implementation guides, visit:
- **[Backend Documentation](backend/README.md)** - API, services, deployment
- **[AI Service Documentation](ai_service/README.md)** - Models, inference, testing

---

### üë®‚Äçüíª Development Team

**tiao051** - Project Creator & Lead Developer

---

### üíñ Built with Passion for a Safer World

**Status**: üîÑ In Active Development | **Last Updated**: November 2025

[![GitHub](https://img.shields.io/badge/GitHub-tiao051-181717?style=for-the-badge&logo=github)](https://github.com/tiao051)
[![Python](https://img.shields.io/badge/Made%20with-Python-3776AB?style=flat-square&logo=python)](https://python.org)
[![License](https://img.shields.io/badge/License-Research-blue?style=flat-square)](LICENSE)

</div>

